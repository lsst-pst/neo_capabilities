
\subsection{Intro and Test Data}

False positives have historically dominated over true transients in previous
surveys. \citep{goldstein15, kessler15}

Major impediment to linking detections of moving objects

Develop a conservative estimate of the FP rate in the LSST stack, using similar
sensors and the current software.

Data from Allen et al., offers a useful cadence. Not the same depth or seeing,
but sufficient to test the software capabilities. Stack has not been optimized
to run at production-levels yet, so this is the starting point of that effort,
not an upper limit on LSST's performance.

\subsection{Processing}

Some reference to LSST software heritage and version, circa Jan 2016.

Differencing two images, rather than a template vs image. Running force
photometry. Ingest into DB.

\subsection{Correlated Noise}

The resulting DIA Source detections are extremely numerous, far above that
expected from both Gaussian noise and from real transients or moving objects.
Counting only positive detections, there are $\sim 20 000$ detections per
square degree, while the number of expected transients is of order hundreds.

\begin{figure}
  \centering
  \plotone{figures/snr_comparison.pdf}
  \caption{
  Histogram of the reported SNR of sources measured in the difference image
  (left), with the expected SNR as estimated from force photometry on the input
  images (right). The blue line indicates the expected SNR distribution based
  on Gaussian noise. The difference between these two histograms illustrates the
  misestimation of the significance of diaSource detections. Using the correct
  SNR values, the vast majority of these detections are $<5 \sigma$ and can be
  disregarded.
  }
  \label{fig:snr_comparison}
\end{figure}

The source of this excess of detections can be seen in
Figure~\ref{fig:snr_comparison}. When the LSST pipeline convolves the science
image to match the PSF of the template image, that smoothing reduces the per
pixel variance in the image. This reduction is reflected in the variance plane
that accompanies each exposure during processing, which is used for estimating
the significance of detections and the uncertainties on source measurements. A
histogram of the number of sources at a given reported SNR (flux over reported
uncertainty) is show in the left panel of Figure~\ref{fig:snr_comparison}. The
blue line shows the expected counts from Gaussian statistics. This distribution
clearly ramps up at much higher reported SNR values than would be expected.

Because we are only differencing two exposures, rather than an exposure against
a coadded template, we can also estimate the significance of any given detection
from the noise in the input images. For each difference image detection, we also
perform force photometry (photometry with the position fixed at the original
difference image detection) on both the ``science'' and ``template'' images. It
is these same pixel values that go into the measurement on the difference image,
but the force photometry is unaffected by convolution with the matching kernel.

The SNR of detections computed through force photometry is shown in the right
panel of Figure~\ref{fig:snr_comparison}. The bulk of these detections are
clearly at much lower significance, and they largely match the increased number
that one would expect from Gaussian statistics if our detection threshold had
been set closer to $4\sigma$.

The underlying cause of this discrepancy between reported SNR values and the
values computed through force photometry lies in the correlation of pixel values
induced by convolution with the matching kernel. While this reduces the per
pixel variance, because neighboring pixels are now correlated, there is an
excess of random fluctuations on the size scale of the PSF over what would be
expected from uncorrelated Gaussian noise. There is thus noise in the
off-diagonal terms of the covariance matrix, which is not tracked.

Tracking the covariance caused by multiple convolutions is a planned feature for
the LSST stack, but is not currently implemented. Previous surveys such as
Pan-STARRS have used small covariance ``pseudo-matricies'', which tracks the
covariance between a small region of neighboring pixels, then assumes that this
relationship between pixels is constant across an image (P. Price, priv. comm.).
This avoids the creation of the full $N_{\rm Pixels}$ by $N_{\rm Pixels}$
covariance matrix, which is impractically large and mostly empty.

For this analysis we will use the significance estimates from the force
photometry, as they reflect the correct measurement uncertainties even though
they are not generated in the same way that will be used in LSST production
runs.


\subsection{False-Positive Results}

Using corrected SNR cut, ~1000 diaSources per square degree (only positive,
ignoring negative). ~500 on best fields.

Many of these are poorly-subtracted stars. To estimate rates of candidate moving
objects, exclude all diaSources that had detections in both direct images (at
the same position). These are still FPs, but they are someone else's FPs.
Resulting levels are ~350 per sq deg. Irreducable noise level is 33/sq deg.

Results from trying to make tracklets, hopefully?? On visual inspection, 25\%
look like junk, 25\% looked like good detections, and the rest were ambiguous
because low SNR. SNR power law exponent is $\sim -2.5$.

Very few detections around bright stars; mostly well-masked by the code. Few
large scale detected artifacts, but not a very big sample of images.

How detailed of a recipe are we providing here; should it be the same level of
detail as we sent to JPL?
